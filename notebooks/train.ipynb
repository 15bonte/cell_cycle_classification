{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train VAE & classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cell_cycle_classification.utils.model_trainer import ModelTrainer\n",
    "from cell_cycle_classification.utils.model_params import FucciVAEModelParams\n",
    "from cell_cycle_classification.utils.parser import FucciVAEParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = FucciVAEModelParams()\n",
    "args = FucciVAEParser().get_default_args()\n",
    "\n",
    "# Define custom paths\n",
    "params.data_dir = \"C:/Users/thoma/data/Data Oriane April/data_repository/all\"\n",
    "params.num_workers = 0  # for some reason, necessary for windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelTrainer()\n",
    "\n",
    "# Next is specific to our data set - modify with your own data set\n",
    "params.train_file = os.path.join(os.path.abspath(''), \"data_set_split\", \"train.txt\")\n",
    "params.val_file = os.path.join(os.path.abspath(''), \"data_set_split\", \"val.txt\")\n",
    "params.test_file = os.path.join(os.path.abspath(''), \"data_set_split\", \"test.txt\")\n",
    "params.data_set_size = 280  # maximum nucleus diameter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE - SSL training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Training VAE on current data set ###\n",
      "\n",
      "Model time id: 20250107-152827-local\n",
      "epochs 10 | batch 32 | lr 0.0001 | weight decay 0.05 | dropout 0.0 | c [0] | z [0, 1, 2, 3, 4] | data set size 280 | latent dim 256 | beta 0.01 | gamma 100.0 | delta 10000.0 | depth 5 | kld loss standard | encoder name resnet18 | latent dim 256 | beta 0.01 | gamma 100.0 | delta 10000.0 | C 50 | depth 5 | kld loss standard | encoder name resnet18\n",
      "File names correctly loaded.\n",
      "Splitting file names ...\n",
      "### Data source ###\n",
      "train data is loaded from c:\\Users\\thoma\\cell_cycle_classification\\notebooks\\data_set_split\\train.txt - 100% elements\n",
      "val data is loaded from c:\\Users\\thoma\\cell_cycle_classification\\notebooks\\data_set_split\\val.txt - 100% elements\n",
      "test data is loaded from c:\\Users\\thoma\\cell_cycle_classification\\notebooks\\data_set_split\\test.txt - 100% elements\n",
      "###################\n",
      "train has 752 images.\n",
      "val has 323 images.\n",
      "test has 388 images.\n",
      "###################\n",
      "Note: test is shuffled for EuclideanMetricMatching computation.\n",
      "Number of parameters in encoder: 11445954\n",
      "Number of parameters in decoder: 13332482\n",
      "Current commit hash: 0594c3d0d41c72530f718bb218d8558109c44016\n",
      "Mean and std are computed on only 10000 images max.\n",
      "Mean/std computation in progress: 100.0% | Image 752/752                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthomas-bonte\u001b[0m (\u001b[33mcbio-bis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\thoma\\cell_cycle_classification\\notebooks\\wandb\\run-20250107_152907-seqlkd61</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cbio-bis/vae-fucci-local/runs/seqlkd61' target=\"_blank\">20250107-152827-local</a></strong> to <a href='https://wandb.ai/cbio-bis/vae-fucci-local' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cbio-bis/vae-fucci-local' target=\"_blank\">https://wandb.ai/cbio-bis/vae-fucci-local</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cbio-bis/vae-fucci-local/runs/seqlkd61' target=\"_blank\">https://wandb.ai/cbio-bis/vae-fucci-local/runs/seqlkd61</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking train dataset...\n",
      "Checking eval dataset...\n",
      "Using Custom Trainer\n",
      "\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created c:\\users\\thoma\\cell_cycle_classification\\cell_cycle_classification\\utils\\..\\..\\models/fucci_vae/20250107-152827-local\\VAMP_training_2025-01-07_15-29-29. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 10\n",
      " - per_device_train_batch_size: 32\n",
      " - per_device_eval_batch_size: 32\n",
      " - checkpoint saving every: None\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.91, 0.995)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      ")\n",
      "Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x0000018786798790>\n",
      "\n",
      "Successfully launched training !\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00407099723815918,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training of epoch 1/10",
       "rate": null,
       "total": 24,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ada38478cc462fbdf10e675eeb811b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 1/10:   0%|          | 0/24 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00500035285949707,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval of epoch 1/10",
       "rate": null,
       "total": 11,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a765e6efc84f59a199e83f656137a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 1/10:   0%|          | 0/11 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 2524.8007\n",
      "Eval loss: 829.7063\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0039997100830078125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training of epoch 2/10",
       "rate": null,
       "total": 24,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9663374d91b40d2853ab304c15262b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 2/10:   0%|          | 0/24 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0039441585540771484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval of epoch 2/10",
       "rate": null,
       "total": 11,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11906874fc7d44b29b855ae83c8f88dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 2/10:   0%|          | 0/11 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 942.0871\n",
      "Eval loss: 591.6669\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004000186920166016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training of epoch 3/10",
       "rate": null,
       "total": 24,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdf11567c2c4eb3ad32295d485e8756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 3/10:   0%|          | 0/24 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005354166030883789,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval of epoch 3/10",
       "rate": null,
       "total": 11,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1566537fdd443b2b1c18a9a1efee203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 3/10:   0%|          | 0/11 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 723.9601\n",
      "Eval loss: 546.5089\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004999876022338867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training of epoch 4/10",
       "rate": null,
       "total": 24,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244ed3c85a724b26945a5f1e56f0d976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 4/10:   0%|          | 0/24 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004996776580810547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval of epoch 4/10",
       "rate": null,
       "total": 11,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba5a8e3b74d4e72bd1aa3970908ba1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 4/10:   0%|          | 0/11 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 535.0652\n",
      "Eval loss: 399.3064\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003999948501586914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training of epoch 5/10",
       "rate": null,
       "total": 24,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620fe7bcfb764f02abd2c87665d4dcd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 5/10:   0%|          | 0/24 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004998207092285156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval of epoch 5/10",
       "rate": null,
       "total": 11,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c2d091fa8849ff84a68a5105146dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 5/10:   0%|          | 0/11 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 482.1482\n",
      "Eval loss: 392.9818\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00800013542175293,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training of epoch 6/10",
       "rate": null,
       "total": 24,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fc395b7cda4ceb9b80701ab56e1696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 6/10:   0%|          | 0/24 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004004001617431641,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval of epoch 6/10",
       "rate": null,
       "total": 11,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae299a636ab4337a2ac94631a230bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 6/10:   0%|          | 0/11 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 417.7291\n",
      "Eval loss: 359.1153\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004999399185180664,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training of epoch 7/10",
       "rate": null,
       "total": 24,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12c9d374a55427ba64bbc04f28a6a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 7/10:   0%|          | 0/24 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0046234130859375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval of epoch 7/10",
       "rate": null,
       "total": 11,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57bd389d2ea4a088d98eb4672390f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 7/10:   0%|          | 0/11 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 375.2895\n",
      "Eval loss: 394.952\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0050008296966552734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training of epoch 8/10",
       "rate": null,
       "total": 24,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02f35be5c684893ae6342de217c6a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 8/10:   0%|          | 0/24 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0059986114501953125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval of epoch 8/10",
       "rate": null,
       "total": 11,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9affe1a99fad41e0b1264a23c18756d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 8/10:   0%|          | 0/11 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 349.0042\n",
      "Eval loss: 320.4879\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00400090217590332,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training of epoch 9/10",
       "rate": null,
       "total": 24,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9425c43352a47b38b942c5fd030277a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 9/10:   0%|          | 0/24 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0039980411529541016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval of epoch 9/10",
       "rate": null,
       "total": 11,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1033c274f4384ee1ba6b873507511856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 9/10:   0%|          | 0/11 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 319.1648\n",
      "Eval loss: 317.2493\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003998994827270508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training of epoch 10/10",
       "rate": null,
       "total": 24,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941ae8d6becf4113bf13e95639980408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 10/10:   0%|          | 0/24 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003998994827270508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval of epoch 10/10",
       "rate": null,
       "total": 11,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5bf2b306364df681f687a034f0cfeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 10/10:   0%|          | 0/11 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 303.2402\n",
      "Eval loss: 353.7705\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in c:\\users\\thoma\\cell_cycle_classification\\cell_cycle_classification\\utils\\..\\..\\models/fucci_vae/20250107-152827-local\\VAMP_training_2025-01-07_15-29-29\\final_model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b2811fe94d469ebc82b0756ebbbee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>additional/eval_epoch_adjacent_loss</td><td>█▅▅▃▂▁▂▂▂▂</td></tr><tr><td>additional/eval_epoch_inactive_dim_loss</td><td>▆▂▁▆▅▆█▃▃▃</td></tr><tr><td>additional/eval_epoch_prediction_loss</td><td>█▆▆▂▃▂▃▁▁▂</td></tr><tr><td>additional/eval_epoch_recon_loss</td><td>█▃▂▂▂▂▂▁▁▁</td></tr><tr><td>additional/eval_epoch_reg_loss</td><td>▁▁▃▃▃▄▅▇▆█</td></tr><tr><td>additional/train_epoch_adjacent_loss</td><td>█▆▅▃▂▂▂▁▁▁</td></tr><tr><td>additional/train_epoch_inactive_dim_loss</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>additional/train_epoch_prediction_loss</td><td>█▅▄▂▂▂▁▁▁▁</td></tr><tr><td>additional/train_epoch_recon_loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>additional/train_epoch_reg_loss</td><td>▁▁▂▃▄▅▆▆▇█</td></tr><tr><td>eval/epoch_loss</td><td>█▅▄▂▂▂▂▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>additional/eval_epoch_adjacent_loss</td><td>26.34748</td></tr><tr><td>additional/eval_epoch_inactive_dim_loss</td><td>0.18182</td></tr><tr><td>additional/eval_epoch_prediction_loss</td><td>170.51931</td></tr><tr><td>additional/eval_epoch_recon_loss</td><td>154.82255</td></tr><tr><td>additional/eval_epoch_reg_loss</td><td>2.08113</td></tr><tr><td>additional/train_epoch_adjacent_loss</td><td>12.64689</td></tr><tr><td>additional/train_epoch_inactive_dim_loss</td><td>0.0</td></tr><tr><td>additional/train_epoch_prediction_loss</td><td>95.7571</td></tr><tr><td>additional/train_epoch_recon_loss</td><td>192.56846</td></tr><tr><td>additional/train_epoch_reg_loss</td><td>2.26775</td></tr><tr><td>eval/epoch_loss</td><td>353.77048</td></tr><tr><td>train/epoch_loss</td><td>303.2402</td></tr><tr><td>train/global_step</td><td>10</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">20250107-152827-local</strong> at: <a href='https://wandb.ai/cbio-bis/vae-fucci-local/runs/seqlkd61' target=\"_blank\">https://wandb.ai/cbio-bis/vae-fucci-local/runs/seqlkd61</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250107_152907-seqlkd61\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation in progress: 100.0% | Batch #12                                                   \n",
      "Average SSIM: 0.448\n",
      "Model evaluation in progress: 100.0% | Batch #12                                                   \n",
      "Average EuclideanMatchingMetric: 0.589\n"
     ]
    }
   ],
   "source": [
    "trainer.ssl_train(args, params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model time id: 20250107-155413-local\n",
      "epochs 10 | batch 64 | lr 0.0001 | weight decay 0.05 | dropout 0.0 | c [0] | z [0, 1, 2, 3, 4] | data set size 280 | latent dim 256 | beta 0.01 | gamma 1 | delta 10000.0 | depth 5 | kld loss standard | encoder name resnet18 | latent dim 256 | beta 0.01 | gamma 1 | delta 10000.0 | C 50 | depth 5 | kld loss standard | encoder name resnet18\n",
      "\n",
      "\n",
      "### Classification ###\n",
      "\n",
      "File names correctly loaded.\n",
      "Splitting file names ...\n",
      "### Data source ###\n",
      "train data is loaded from c:\\Users\\thoma\\cell_cycle_classification\\notebooks\\data_set_split\\train.txt - 100% elements\n",
      "val data is loaded from c:\\Users\\thoma\\cell_cycle_classification\\notebooks\\data_set_split\\val.txt - 100% elements\n",
      "test data is loaded from c:\\Users\\thoma\\cell_cycle_classification\\notebooks\\data_set_split\\test.txt - 100% elements\n",
      "###################\n",
      "train has 171 images for class 0, 347 images for class 1, 234 images for class 2, total 752 images (oversampling applied)\n",
      "val has 62 images for class 0, 177 images for class 1, 84 images for class 2, total 323 images\n",
      "test has 81 images for class 0, 192 images for class 1, 115 images for class 2, total 388 images\n",
      "###################\n",
      "Number of parameters to train: 11512517\n",
      "Current commit hash: 0594c3d0d41c72530f718bb218d8558109c44016\n",
      "Training in progress: 80.0% | Local step 12 | Epoch 8                                              "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m params\u001b[38;5;241m.\u001b[39mreset_training_folders()  \u001b[38;5;66;03m# necessary since model folder is not defined from args but in params directly\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassification_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\thoma\\cell_cycle_classification\\cell_cycle_classification\\utils\\model_trainer.py:215\u001b[0m, in \u001b[0;36mModelTrainer.classification_train\u001b[1;34m(self, args, params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display_latent_space_umap(params)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### Classification ###\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_core_classification_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\thoma\\cell_cycle_classification\\cell_cycle_classification\\utils\\model_trainer.py:279\u001b[0m, in \u001b[0;36mModelTrainer._core_classification_train\u001b[1;34m(self, params, args)\u001b[0m\n\u001b[0;32m    272\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(\n\u001b[0;32m    273\u001b[0m     model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[0;32m    274\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(params\u001b[38;5;241m.\u001b[39mlearning_rate),\n\u001b[0;32m    275\u001b[0m     betas\u001b[38;5;241m=\u001b[39m(params\u001b[38;5;241m.\u001b[39mbeta1, params\u001b[38;5;241m.\u001b[39mbeta2),\n\u001b[0;32m    276\u001b[0m )  \u001b[38;5;66;03m# define the optimization\u001b[39;00m\n\u001b[0;32m    277\u001b[0m loss_function \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()  \u001b[38;5;66;03m# define the loss function\u001b[39;00m\n\u001b[1;32m--> 279\u001b[0m \u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmean_std_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean_std.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# done to avoid usual mean_std computation\u001b[39;49;00m\n\u001b[0;32m    287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPredicting with early stopping model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# Update model with saved one\u001b[39;00m\n",
      "File \u001b[1;32m~\\cnn_framework\\src\\cnn_framework\\utils\\model_managers\\model_manager.py:450\u001b[0m, in \u001b[0;36mModelManager.fit\u001b[1;34m(self, train_dl, val_dl, optimizer, loss_function, lr_scheduler, mean_std_path)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loss_manager \u001b[38;5;241m=\u001b[39m LossManager(loss_function)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# Core fit function with training loop\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    453\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32m~\\cnn_framework\\src\\cnn_framework\\utils\\model_managers\\model_manager.py:318\u001b[0m, in \u001b[0;36mModelManager.fit_core\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# set model to evaluation mode\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 318\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dl_element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    319\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(\n\u001b[0;32m    320\u001b[0m             dl_element,\n\u001b[0;32m    321\u001b[0m             val_metric,\n\u001b[0;32m    322\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    323\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loss_manager,\n\u001b[0;32m    324\u001b[0m         )\n\u001b[0;32m    325\u001b[0m         val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\users\\thoma\\cell_cycle_classification\\cell_cycle_classification\\utils\\data_set.py:261\u001b[0m, in \u001b[0;36mFucciClassificationDataSet.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Read file and generate images\u001b[39;00m\n\u001b[1;32m--> 261\u001b[0m     data_set_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_images\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# Apply transforms\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_transforms(data_set_output)\n",
      "File \u001b[1;32mc:\\users\\thoma\\cell_cycle_classification\\cell_cycle_classification\\utils\\data_set.py:253\u001b[0m, in \u001b[0;36mFucciClassificationDataSet.generate_images\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_images\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;66;03m# Output\u001b[39;00m\n\u001b[0;32m    250\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_output(filename)\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DatasetOutput(\n\u001b[1;32m--> 253\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_data_source\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh5_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh5_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh5_names\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    256\u001b[0m         target_array\u001b[38;5;241m=\u001b[39mprobabilities,\n\u001b[0;32m    257\u001b[0m     )\n",
      "File \u001b[1;32m~\\cnn_framework\\src\\cnn_framework\\utils\\readers\\images_reader.py:73\u001b[0m, in \u001b[0;36mImagesReader.get_image\u001b[1;34m(self, filename, respect_initial_type, axis_to_merge, for_training, h5_file, names)\u001b[0m\n\u001b[0;32m     64\u001b[0m     image_reader \u001b[38;5;241m=\u001b[39m H5Reader(\n\u001b[0;32m     65\u001b[0m         h5_file,\n\u001b[0;32m     66\u001b[0m         names,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m         respect_initial_type\u001b[38;5;241m=\u001b[39mrespect_initial_type,\n\u001b[0;32m     71\u001b[0m     )\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m     image_reader \u001b[38;5;241m=\u001b[39m \u001b[43mTiffReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprojection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrespect_initial_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrespect_initial_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m raw_image \u001b[38;5;241m=\u001b[39m image_reader\u001b[38;5;241m.\u001b[39mget_processed_image()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_image\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m:\n",
      "File \u001b[1;32m~\\cnn_framework\\src\\cnn_framework\\utils\\readers\\abstract_reader.py:43\u001b[0m, in \u001b[0;36mAbstractReader.__init__\u001b[1;34m(self, file_path, normalize, project, respect_initial_type)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     37\u001b[0m     file_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m ):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# Read image from file\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# Type management\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m respect_initial_type:\n",
      "File \u001b[1;32m~\\cnn_framework\\src\\cnn_framework\\utils\\readers\\tiff_reader.py:20\u001b[0m, in \u001b[0;36mTiffReader._read_image\u001b[1;34m(self, file_path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m     18\u001b[0m     aics_img \u001b[38;5;241m=\u001b[39m AICSImage(file_path)\n\u001b[0;32m     19\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreorganize_channels(\n\u001b[1;32m---> 20\u001b[0m         \u001b[43maics_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTCZYX\u001b[39m\u001b[38;5;124m\"\u001b[39m, aics_img\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39morder\n\u001b[0;32m     21\u001b[0m     )\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\aicsimageio\\aics_image.py:542\u001b[0m, in \u001b[0;36mAICSImage.data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03m    Recommended to use `dask_data` for large mosaic images.\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxarray_data\u001b[49m\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\aicsimageio\\aics_image.py:501\u001b[0m, in \u001b[0;36mAICSImage.xarray_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    494\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_data_array_to_aics_image_standard(\n\u001b[0;32m    495\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mxarray_data\n\u001b[0;32m    496\u001b[0m             )\n\u001b[0;32m    497\u001b[0m         )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_data_array_to_aics_image_standard(\n\u001b[1;32m--> 501\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxarray_data\u001b[49m\n\u001b[0;32m    502\u001b[0m     )\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# Remake the delayed xarray dataarray object using a rechunked dask array\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# from the just retrieved in-memory xarray dataarray\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_dask_data \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(\n\u001b[0;32m    507\u001b[0m     da\u001b[38;5;241m.\u001b[39mfrom_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mdata),\n\u001b[0;32m    508\u001b[0m     dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mdims,\n\u001b[0;32m    509\u001b[0m     coords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mcoords,\n\u001b[0;32m    510\u001b[0m     attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mattrs,\n\u001b[0;32m    511\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\aicsimageio\\readers\\reader.py:372\u001b[0m, in \u001b[0;36mReader.xarray_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03mReturns\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m-------\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;124;03mxarray_data: xr.DataArray\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m    The fully read image and metadata as an annotated data array.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_immediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;66;03m# Remake the delayed xarray dataarray object using a rechunked dask array\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;66;03m# from the just retrieved in-memory xarray dataarray\u001b[39;00m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_dask_data \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(\n\u001b[0;32m    377\u001b[0m         da\u001b[38;5;241m.\u001b[39mfrom_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mdata),\n\u001b[0;32m    378\u001b[0m         dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mdims,\n\u001b[0;32m    379\u001b[0m         coords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mcoords,\n\u001b[0;32m    380\u001b[0m         attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xarray_data\u001b[38;5;241m.\u001b[39mattrs,\n\u001b[0;32m    381\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\aicsimageio\\readers\\ome_tiff_reader.py:372\u001b[0m, in \u001b[0;36mOmeTiffReader._read_immediate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    367\u001b[0m dims \u001b[38;5;241m=\u001b[39m OmeTiffReader\u001b[38;5;241m.\u001b[39m_guess_ome_dim_order(\n\u001b[0;32m    368\u001b[0m     tiff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ome, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_scene_index\n\u001b[0;32m    369\u001b[0m )\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# Read image into memory\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m image_data \u001b[38;5;241m=\u001b[39m \u001b[43mtiff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_scene_index\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_general_data_array_constructor(\n\u001b[0;32m    375\u001b[0m     image_data,\n\u001b[0;32m    376\u001b[0m     dims,\n\u001b[0;32m    377\u001b[0m     coords,\n\u001b[0;32m    378\u001b[0m     tiff_tags,\n\u001b[0;32m    379\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\tifffile\\tifffile.py:11563\u001b[0m, in \u001b[0;36mTiffPageSeries.asarray\u001b[1;34m(self, level, **kwargs)\u001b[0m\n\u001b[0;32m  11561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m  11562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels[level]\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m> 11563\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39masarray(series\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m  11564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m  11565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(result)\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\tifffile\\tifffile.py:4207\u001b[0m, in \u001b[0;36mTiffFile.asarray\u001b[1;34m(self, key, series, level, squeeze, out, maxworkers)\u001b[0m\n\u001b[0;32m   4205\u001b[0m     result \u001b[38;5;241m=\u001b[39m page0\u001b[38;5;241m.\u001b[39masarray(out\u001b[38;5;241m=\u001b[39mout, maxworkers\u001b[38;5;241m=\u001b[39mmaxworkers)\n\u001b[0;32m   4206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4207\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mstack_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxworkers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\tifffile\\tifffile.py:21845\u001b[0m, in \u001b[0;36mstack_pages\u001b[1;34m(pages, tiled, lock, maxworkers, out, **kwargs)\u001b[0m\n\u001b[0;32m  21843\u001b[0m         page0\u001b[38;5;241m.\u001b[39mdecode  \u001b[38;5;66;03m# init TiffPage.decode function\u001b[39;00m\n\u001b[0;32m  21844\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(maxworkers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m> 21845\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnpages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m  21846\u001b[0m                 \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m  21848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m  21849\u001b[0m     \u001b[38;5;66;03m# TODO: not used or tested\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\concurrent\\futures\\_base.py:598\u001b[0m, in \u001b[0;36mExecutor.map\u001b[1;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    596\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 598\u001b[0m fs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(fn, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39miterables)]\n\u001b[0;32m    600\u001b[0m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult_iterator\u001b[39m():\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\concurrent\\futures\\_base.py:598\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    596\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 598\u001b[0m fs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39miterables)]\n\u001b[0;32m    600\u001b[0m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult_iterator\u001b[39m():\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\concurrent\\futures\\thread.py:176\u001b[0m, in \u001b[0;36mThreadPoolExecutor.submit\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m w \u001b[38;5;241m=\u001b[39m _WorkItem(f, fn, args, kwargs)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_work_queue\u001b[38;5;241m.\u001b[39mput(w)\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adjust_thread_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\concurrent\\futures\\thread.py:199\u001b[0m, in \u001b[0;36mThreadPoolExecutor._adjust_thread_count\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    192\u001b[0m thread_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_name_prefix \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    193\u001b[0m                          num_threads)\n\u001b[0;32m    194\u001b[0m t \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mThread(name\u001b[38;5;241m=\u001b[39mthread_name, target\u001b[38;5;241m=\u001b[39m_worker,\n\u001b[0;32m    195\u001b[0m                      args\u001b[38;5;241m=\u001b[39m(weakref\u001b[38;5;241m.\u001b[39mref(\u001b[38;5;28mself\u001b[39m, weakref_cb),\n\u001b[0;32m    196\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_work_queue,\n\u001b[0;32m    197\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initializer,\n\u001b[0;32m    198\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initargs))\n\u001b[1;32m--> 199\u001b[0m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads\u001b[38;5;241m.\u001b[39madd(t)\n\u001b[0;32m    201\u001b[0m _threads_queues[t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_work_queue\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\threading.py:904\u001b[0m, in \u001b[0;36mThread.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m _limbo[\u001b[38;5;28mself\u001b[39m]\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_started\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params.reset_training_folders()  # necessary since model folder is not defined from args but in params directly\n",
    "trainer.classification_train(args, params);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
